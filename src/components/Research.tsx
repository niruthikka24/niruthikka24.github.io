import React from 'react';
export function Research() {
  const researchAreas = [{
    title: 'Explainable Artificial Intelligence for Medical Image Analysis',
    description: 'The primary focus is on developing interpretable AI systems for medical image analysis, specifically targeting cervical cancer detection through advanced image segmentation techniques. This work addresses the critical need for transparency in AI-driven medical diagnostics by creating explainable models that can provide clear reasoning for their classification decisions. The research integrates explainable AI (XAI) methods with computer vision techniques to enable precise segmentation of cellular structures, contributing to more reliable and trustworthy automated medical diagnosis systems.',
    topics: [
      <>
        Conducted research under the supervision of{" "}
        <a href="https://scholar.google.com/citations?user=DEUAL1UAAAAJ&hl=en&oi=ao" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">
          Prof. Dulani Meedeniya
        </a>, in collaboration with the{" "}
        <a href="https://sites.google.com/cse.mrt.ac.lk/biohealth/home/imaging/cervical-cancer-screening-using-explainability" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">
          BioHealth Informatics Group 
        </a>{" and "}
        <a href="https://pure.ulster.ac.uk/en/persons/pratheepan-yogarajah" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">
          Ulster University
        </a>, United Kingdom.
      </>,
      "Published 2 conference papers and a Q1 journal article based on this work.", 'Designed and implemented two new algorithms, integrating GradCAM, LRP, GraphCut, and multiple clustering techniques, for a novel segmentation framework.', 'Built and deployed a comprehensive web-based software system for clinical usability.'
    ],
  }, {
    title: 'Error Detection and Visualization in Large Language Model Reasoning',
    description: 'My current collaborative research involves developing systematic approaches to identify and visualize errors in the complex reasoning chains generated by Large Language Models (LLMs). Working as part of a research team, this project addresses a critical challenge in AI reliability by creating methods to detect flaws in long Chain-of-Thought (CoT) reasoning processes and presenting these findings through intuitive visual interfaces. The collaborative effort aims to enhance the interpretability and trustworthiness of LLM outputs by providing users with clear, actionable insights into where and why reasoning errors occur, ultimately facilitating more effective debugging and model improvement.',
    topics: [
      <>
        Currently collaborating with{" "}
        <a href="https://csw0109.github.io/" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">
          Shiwei Chen
        </a>{" "} (master's student researcher) under{" "}
        <a href="https://yong-wang.org/index.html" target="_blank" rel="noopener noreferrer" className="text-blue-600 underline">
          Prof. Yong Wang 
        </a>{" "}at Nanyang Technological University (NTU)
      </>,
      , "Contributing to the emerging field of LLM debugging and interpretability (ongoing work)"]
  }];
  return <div className="max-w-4xl mx-auto">
      <h1 className="text-3xl font-semibold mb-8">Research</h1>
      <div className="prose prose-lg mb-10">
        <p>
          My research interests center on developing innovative human-centric visualization systems for diverse applications across multiple domains. I am passionate about creating novel visual interfaces and representation methods that transform complex data and processes into intuitive, actionable insights for users. Through my work spanning medical imaging, large language models, and emerging applications, I explore how thoughtful visualization design can enhance decision-making and understanding across various fields. Within this broader focus, I am particularly interested in leveraging visualization techniques to explore AI system internals, contributing to explainability and safety research. As I continue to develop my research trajectory, I remain committed to building visualization solutions that empower users to better understand and interact with complex systems and data.
        </p>
      </div>
      <div className="space-y-12">
        {researchAreas.map((area, index) => <div key={index} className="border-t border-gray-200 pt-8">
            <h2 className="text-2xl font-medium mb-4">{area.title}</h2>
            <p className="text-gray-700 mb-6">{area.description}</p>
            <h3 className="text-lg font-medium mb-3">Research Highlights:</h3>
            <ul className="list-disc pl-5 space-y-2">
              {area.topics.map((topic, topicIndex) => <li key={topicIndex} className="text-gray-700">
                  {topic}
                </li>)}
            </ul>
          </div>)}
      </div>
      {/* <div className="mt-12 border-t border-gray-200 pt-8">
        <h2 className="text-2xl font-medium mb-4">Research Philosophy</h2>
        <p className="text-gray-700">
          My approach to research is guided by [your research philosophy or
          principles]. I believe in [key values or methodological commitments
          that shape your work]. Through my research, I aim to [broader goals or
          impacts you hope to achieve].
        </p>
      </div> */}
    </div>;
}